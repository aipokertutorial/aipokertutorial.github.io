---
title: "AIPT Section 2.2: Game Theory -- Trees in Games"
date: 2020-10-20
sidebar:
  nav: "nav"
toc: true
toc_sticky: true
toc_label: "TOC"
author_profile: false
---

<!-- 
Exploitation vs. exploration (restaurant, ads, oil locations, best moves in games)
-->

# Game Theory -- Trees in Games
Many games can be solved using the minimax algorithm for exploring a tree and determining the best move from each position. 

## Basic Tree
Take a look at the game tree below. The circular nodes represent player positions and the lines represent possible actions. The "root" of the tree is the initial state at the top. We have P1 acting first, P2 acting second, and the payoffs at the leaf nodes in the standard P1, P2 format. 

![Minimax tree](../assets/section2/trees/minimax.png)

The standard way to solve a tree like this is using **backward induction**, whereby we start with the leaves (i.e. the payoff nodes at the bottom) of the tree and see which decisions the last player, Player 2 in this case, will make at her decision nodes. 

Player 2's goal is to minimize the maximum payoff of Player 1, which in the zero-sum setting is equivalent to minimizing her own maximum loss or maximizing her own minimum payoff. This is equivalent to a Nash equilibrium in the zero-sum setting. 

She picks the right node on the left side (payoff -1 instead of -5) and the left node on the right side (payoff 3 instead of -6). 

These values are then propagated up the tree so from Player 1's perspective, the value of going left is 1 and of going right is -3. The other leaf nodes are not considered because Player 2 will never choose those. Player 1 then decides to play left to maximize his payoff. 

![Minimax tree solved](../assets/section2/trees/minimax2.png)

We can see all possible payouts, where the rows are P1 actions and the columns are P2 actions after P1 actions (e.g. Left/Left means P1 chose Left and then P2 also chose Left).

| P1/P2  | Left/Left | Left/Right | Right/Left | Right/Right |
|---|---|---|---|---|
| Left  | 5,-5  | 5,-5  | 1,-1  | 1,-1 |
| Right  | -3,3  | -3,3 | 6,-6  | 6,-6 |

Note that Player 1 choosing right *could* result in a higher payout (6) if Player 2 also chose right, but a rational Player 2 would not do that, and so the algorithm requires maximizing one's minimum payoff, which means Player 1 must choose left (earning a guaranteed value of 1). 

By working backwards from the end of a game, we can evaluate each possible sequence of moves and propagate the values up the game tree.

**Subgame perfect equilibrium** means that each subgame, which is a decision state in the above game tree, is a Nash equilibrium. The strategy of P1 choosing Left and P2 choosing Right after Left and Left after Right is a subgame perfect equilibrium. 

 Two main problems arise with minimax and backward induction. 

### Problem 1: The Game is too Damn Large

In theory, we could use the minimax algorithm to solve games like chess. The problem is that the game and the space of possible actions is HUGE. It's not feasible to evaluate all possibilities. The first level of the tree would need to have every possible action and then the next level would have every possible action from each of those actions, and so on. Even checkers is very large, though smaller games like tic tac toe can be solved with minimax. More sophisticated methods and approximation techniques are used in practice for large games. One simple method is to only go down the tree to a depth of "X" and then approximate the value of the states there. 

### Problem 2: Perfect Information vs. Imperfect Information

What about poker? Real poker games like Texas Hold'em are very large and run into the same problem we have with games like chess, but in addition, poker is an **imperfect information game** and games like chess and tic tac toe are **perfect information games**. The distinction is that in poker there is hidden information -- each player's private cards. In perfect information games, all players see all of the information. 

With perfect information, each player knows exactly what node/state he is in in the game tree. With imperfect information, there is uncertainty about the state of the game because the other player's cards are unknown.

## Poker Tree

Below we show the game tree for 1-card poker. In brief, it's a 1v1 game where each player starts with $2 and antes $1, leaving a single $1 bet remaining. We'll go into more details in the next section. 

The top node is a chance node that "deals" the cards. To make it more readable, only 2 chance outcomes are shown, Player 1 dealt Q with Player 2 dealt J and Player 1 dealt Q with Player 2 dealt K. 

![1-card poker game tree](../assets/section2/trees/infoset2.png)

Player 1's initial action is to either bet or pass. If Player 1 bets, Player 2 can call or fold. If Player 1 passes, Player 2 can bet or pass. If Player 1 passed and Player 2 bet, then Player 1 can call or fold. 

Note the nodes that are circled and connected by a line. This means that they are in the same **information set**. An information set consists of equivalent states based on information known to that player. For example, in the top information set, Player 1 has a Q in both of the shown states, so his actions will be the same in both even though Player 2 could have either a K or J. The information known to Player 1 is "Card Q, starting action". At the later information set, the information known is "Card Q, I pass, opponent bets". All decisions must be made based only on information known to each player! However, these are actually different true game states.

Looking at the information set at the bottom where Player 1 passes and Player 2 bets, Player 1 has the same information in both cases, but calling when Player 2 has a J means winning 2 and calling when Player 2 has a K means losing 2. The payoffs are completely different! 

Therefore we can't simply propagate values up the tree as we can do in perfect information games. Later in the tutorial, we will discuss CFR (counterfactual regret minimization), which is a way to solve games like poker that can't be solved using minimax. 

## Tic Tac Toe Tree

**Tree goes here**

On the tic tac toe tree, from the initial state, there are up to 9 levels of moves. Each subsequent level has fewer possible actions since more spaces on the game board are taken as we go down the tree. The tree ends at points either where the game is over because one player wins or when all the spaces are filled and no one has won, resulting in a tie. 

In tic tac toe, the sequence of actions prior to a certain game state are not important. 

## Tic Tac Toe Python Implementations
While we're mainly focused in this tutorial on poker and imperfect information games, we take a short detour to look more in-depth at minimax and Monte Carlo Tree Search (MCTS) through the lens of tic tac toe. 

### Tic Tac Toe in Python
Below we show a basic Python class called Tictactoe. The board is initialized with all 0's and each player is represented by a 1 or -1. Those numbers go into board spaces when the associated player makes a move. The class has 5 functions: 

1. make_move: Enters the player's move onto the board if the space is available and advances the play to the next player
2. new_state_with_move: Same as make_move, but returns a copy of the board with the new move instead of the original board
3. available_moves: Lists the moves that are currently available on the board
4. check_result: Checks every possible winning sequence and returns either the winning player's ID if there is a winner, a 0 if the game has ended in a tie, or None if the game is not over yet
5. repr: Used for printing the board. Empty slots are represented by their number from 0 to 8, player 1 is represented with 'x', player 2 is represented with 'o', and a line break is added as needed after the first 3 and middle 3 positions.

We also have two simple agent classes: 
1. HumanAgent: Enters a move from 0-8 and the move is placed if it's available, otherwise we ask for the move again
2. RandomAgent: Randomly selects a move from the available moves

Finally, we need another function to actually run the game. 

```python 
class Tictactoe:
	def __init__(self, board = [0] * 9, acting_player = 1):
		self.board = board
		self.acting_player = acting_player

	def make_move(self, move):
		if move in self.available_moves():
			self.board[move] = self.acting_player
			self.acting_player = 0 - self.acting_player #Players are 1 or -1

	def new_state_with_move(self, move): #Return new ttt state with move, but don't change this state
		if move in self.available_moves():
			board_copy = copy.deepcopy(self.board)
			board_copy[move] = self.acting_player
			return Tictactoe(board_copy, 0 - self.acting_player)
			
	def available_moves(self):
		return [i for i in range(9) if self.board[i] == 0]
	
	def check_result(self):
		for (a,b,c) in [(0,1,2),(3,4,5),(6,7,8),(0,3,6),(1,4,7),(2,5,8),(0,4,8),(2,4,6)]:
			if self.board[a] == self.board[b] == self.board[c] != 0:
				return self.board[a]
		if self.available_moves() == []: return 0 #Tie
		return None #Game not over
		
	def __repr__(self):
		s= ""
		for i in range(9): 
			if self.board[i] == 0:
				s+=str(i)
			elif self.board[i] == 1:
				s+='x'
			elif self.board[i] == -1:
				s+='o'
			if i == 2 or i == 5: s += "\n"
		return s
```
```python
class HumanAgent:
	def select_move(self, game_state):
		print('Enter your move (0-8): ')
		move = int(float(input()))
		#print('move', move)
		#print('game state available moves', game_state.available_moves())
		if move in game_state.available_moves():
			return move
		else:
			print('Invalid move, try again')
			self.select_move(game_state)
```

```python
class RandomAgent:
	def select_move(self, game_state):
		return random.choice(game_state.available_moves())
```

```python
if __name__ == "__main__":
	ttt = Tictactoe() 
  #ttt = Tictactoe([0,0,-1,0,0,0,1,-1,1]) #Optionally can start from a pre-set game position
	h = HumanAgent()
  r = RandomAgent()
```


### Minimax Applied to Tic Tac Toe
We can apply the minimax algorithm to tic tac toe. Here we use a simplified version of minimax called negamax, because in a zero-sum game like tic tac toe, the value of a position to one player is the negative value to the other player. 

```python
class NegamaxAgent:
	def __init__(self):
		self.memo = {} #move, value

	def negamax(self, game_state):
		if game_state not in self.memo: #already visited this state?
			result = game_state.check_result()
			if result is not None: #leaf node or end of search
				best_move = None
				best_val = result * game_state.acting_player #return 0 for tie or 1 for maximizing win or -1 for minimizing win
			else:
				best_val = float('-inf')
				for i in game_state.available_moves():
					clone_state = copy.deepcopy(game_state)
					clone_state.make_move(i) #makes move and switches to next player
					_, val = self.negamax(clone_state)
					val *= -1 
					if val > best_val:
						best_move = i
						best_val = val	
			self.memo[game_state] = (best_move, best_val)
		return self.memo[game_state]
```

### Monte Carlo Tree Search (MCTS) Applied to Tic Tac Toe

as a way to deal with otherwise intractably large game trees. 